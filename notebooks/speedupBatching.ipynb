{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from alpha_connect import AlphaZeroModelConnect4, RandomAgent, state_to_supervised_input\n",
    "import time\n",
    "from game import ConnectState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10000 random states\n",
    "states = set()\n",
    "random_agent = RandomAgent()\n",
    "state = ConnectState.sample_initial_state()\n",
    "while len(states) < 4096:\n",
    "    if state.has_ended:\n",
    "        state = ConnectState.sample_initial_state()\n",
    "    states.add(state)\n",
    "\n",
    "    action = random_agent.sample_move(state)\n",
    "    state = action.sample_next_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4096 states in 2.6952261924743652 seconds with batch size 4096\n",
      "Processed 4096 states in 6.91292405128479 seconds with batch size 2048\n",
      "Processed 4096 states in 2.618597984313965 seconds with batch size 1024\n",
      "Processed 4096 states in 2.1275992393493652 seconds with batch size 512\n",
      "Processed 4096 states in 2.1979100704193115 seconds with batch size 256\n",
      "Processed 4096 states in 2.2819929122924805 seconds with batch size 128\n",
      "Processed 4096 states in 2.568247079849243 seconds with batch size 64\n",
      "Processed 4096 states in 3.096703052520752 seconds with batch size 32\n",
      "Processed 4096 states in 5.507427930831909 seconds with batch size 16\n",
      "Processed 4096 states in 10.644919157028198 seconds with batch size 8\n",
      "Processed 4096 states in 21.00096321105957 seconds with batch size 4\n",
      "Processed 4096 states in 41.22349309921265 seconds with batch size 2\n",
      "Processed 4096 states in 83.01374006271362 seconds with batch size 1\n"
     ]
    }
   ],
   "source": [
    "model = AlphaZeroModelConnect4()\n",
    "model.load_state_dict(torch.load(\"../data/latest.pth\"))\n",
    "model.to(\"mps\")\n",
    "\n",
    "batch_sizes = [4096, 2048, 1024, 512, 256, 128, 64, 32, 16, 8, 4, 2, 1]\n",
    "states = list(states)\n",
    "for batch_size in batch_sizes:\n",
    "    start_time = time.time()\n",
    "    for i in range(0, len(states), batch_size):\n",
    "        input_tensor = [\n",
    "            state_to_supervised_input(state) for state in states[i : i + batch_size]\n",
    "        ]\n",
    "        input_tensor = (\n",
    "            torch.stack(input_tensor)\n",
    "            .type(torch.float32)\n",
    "            .view(batch_size, 3, 6, 7)\n",
    "            .to(\"mps\")\n",
    "        )\n",
    "        a, b = model(input_tensor)\n",
    "    print(\n",
    "        f\"Processed {len(states)} states in {time.time()-start_time} seconds with batch size {batch_size}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
