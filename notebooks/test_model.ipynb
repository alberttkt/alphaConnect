{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import utils, Tensor, abs\n",
    "import torch\n",
    "import lightning as L\n",
    "import pandas as pd\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "from alpha_connect import AlphaZeroModelConnect4, MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alberttroussard/Documents/alpha-connect/notebooks/../data\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"..\", \"data\")\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data.csv\n",
    "\n",
    "\n",
    "data = pd.read_csv(os.path.join(data_path, \"../data/data2.csv\"))\n",
    "# shuffle the data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "x = data.iloc[:, :-8].values\n",
    "\n",
    "policy = data.iloc[:, -8:-1].values\n",
    "\n",
    "value = data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "dataset = MyDataset(Tensor(x), Tensor(policy), Tensor(value))\n",
    "\n",
    "loader = utils.data.DataLoader(dataset, batch_size=1, num_workers=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlphaZeroModelConnect4()\n",
    "model.load_state_dict(torch.load(\"../data/latest.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: tensor([0., 1., 0., 0., 0., 0., 0.])\n",
      "Predicted policy: tensor([ 3.5453e-04, -2.2529e-02,  2.0387e-02,  6.6434e-02,  8.6767e-01,\n",
      "         9.2018e-03,  3.3982e-03], grad_fn=<SelectBackward0>)\n",
      "Value: 1\n",
      "Predicted value: -0.7925336360931396\n",
      "Policy: tensor([0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333])\n",
      "Predicted policy: tensor([ 0.0032, -0.0263,  0.0118,  0.2688,  0.6456,  0.1026, -0.0372],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Value: 1\n",
      "Predicted value: 0.5067662596702576\n",
      "Policy: tensor([0., 0., 0., 1., 0., 0., 0.])\n",
      "Predicted policy: tensor([-0.0168, -0.0096,  0.0987,  0.7362,  0.0627,  0.1296, -0.0050],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Value: -1\n",
      "Predicted value: -0.3587665855884552\n",
      "Policy: tensor([0., 1., 0., 0., 0., 0., 0.])\n",
      "Predicted policy: tensor([-0.0163,  0.0385, -0.0101,  0.4540,  0.2260,  0.2447, -0.0105],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Value: -1\n",
      "Predicted value: 0.8817331194877625\n",
      "Policy: tensor([0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.1667, 0.1667])\n",
      "Predicted policy: tensor([ 0.0018, -0.0058,  0.0320, -0.0293,  1.0336, -0.0231, -0.0103],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Value: 1\n",
      "Predicted value: 0.9134383201599121\n",
      "Value Accuracy: 34.4\n",
      "Accuracy: 34.2\n",
      "{0: 38, 1: 106, 2: 131, 3: 312, 4: 201, 5: 168, 6: 44}\n",
      "Value Accuracy: 34.6\n",
      "Accuracy: 34.6\n",
      "{0: 80, 1: 191, 2: 251, 3: 650, 4: 426, 5: 320, 6: 82}\n",
      "Value Accuracy: 34.43333333333333\n",
      "Accuracy: 34.56666666666667\n",
      "{0: 114, 1: 290, 2: 395, 3: 973, 4: 617, 5: 484, 6: 127}\n",
      "Value Accuracy: 34.825\n",
      "Accuracy: 34.575\n",
      "{0: 158, 1: 381, 2: 533, 3: 1281, 4: 831, 5: 638, 6: 178}\n",
      "Value Accuracy: 34.94\n",
      "Accuracy: 34.1\n",
      "{0: 189, 1: 491, 2: 681, 3: 1621, 4: 1012, 5: 788, 6: 218}\n",
      "Value Accuracy: 35.11666666666667\n",
      "Accuracy: 34.483333333333334\n",
      "{0: 217, 1: 589, 2: 830, 3: 1938, 4: 1211, 5: 954, 6: 261}\n",
      "Value Accuracy: 35.214285714285715\n",
      "Accuracy: 34.65714285714286\n",
      "{0: 243, 1: 678, 2: 996, 3: 2249, 4: 1412, 5: 1134, 6: 288}\n",
      "Value Accuracy: 35.85\n",
      "Accuracy: 34.85\n",
      "{0: 292, 1: 770, 2: 1171, 3: 2527, 4: 1620, 5: 1297, 6: 323}\n",
      "Value Accuracy: 35.77777777777778\n",
      "Accuracy: 34.9\n",
      "{0: 327, 1: 886, 2: 1326, 3: 2827, 4: 1799, 5: 1465, 6: 370}\n",
      "Value Accuracy: 35.75\n",
      "Accuracy: 34.98\n",
      "{0: 359, 1: 967, 2: 1493, 3: 3171, 4: 1988, 5: 1614, 6: 408}\n",
      "Value Accuracy: 35.654545454545456\n",
      "Accuracy: 34.92727272727273\n",
      "{0: 399, 1: 1069, 2: 1631, 3: 3497, 4: 2188, 5: 1764, 6: 452}\n",
      "Value Accuracy: 35.78333333333333\n",
      "Accuracy: 34.75\n",
      "{0: 445, 1: 1159, 2: 1783, 3: 3802, 4: 2398, 5: 1919, 6: 494}\n",
      "Value Accuracy: 35.69230769230769\n",
      "Accuracy: 34.69230769230769\n",
      "{0: 478, 1: 1242, 2: 1935, 3: 4111, 4: 2605, 5: 2092, 6: 537}\n",
      "Value Accuracy: 35.68571428571428\n",
      "Accuracy: 34.66428571428571\n",
      "{0: 521, 1: 1341, 2: 2085, 3: 4428, 4: 2796, 5: 2250, 6: 579}\n",
      "Value Accuracy: 35.63333333333333\n",
      "Accuracy: 34.82\n",
      "{0: 577, 1: 1438, 2: 2215, 3: 4767, 4: 2992, 5: 2402, 6: 609}\n",
      "Value Accuracy: 35.59375\n",
      "Accuracy: 34.825\n",
      "{0: 616, 1: 1537, 2: 2348, 3: 5073, 4: 3205, 5: 2569, 6: 652}\n",
      "Value Accuracy: 35.49411764705882\n",
      "Accuracy: 34.911764705882355\n",
      "{0: 649, 1: 1622, 2: 2507, 3: 5388, 4: 3391, 5: 2751, 6: 692}\n",
      "Value Accuracy: 35.422222222222224\n",
      "Accuracy: 34.74444444444445\n",
      "{0: 687, 1: 1734, 2: 2642, 3: 5693, 4: 3580, 5: 2926, 6: 738}\n",
      "Value Accuracy: 35.36842105263158\n",
      "Accuracy: 34.747368421052634\n",
      "{0: 720, 1: 1839, 2: 2789, 3: 6016, 4: 3765, 5: 3105, 6: 766}\n",
      "Value Accuracy: 35.305\n",
      "Accuracy: 34.77\n",
      "{0: 751, 1: 1935, 2: 2943, 3: 6325, 4: 3966, 5: 3276, 6: 804}\n",
      "Value Accuracy: 35.41904761904762\n",
      "Accuracy: 34.733333333333334\n",
      "{0: 790, 1: 2029, 2: 3083, 3: 6651, 4: 4152, 5: 3456, 6: 839}\n",
      "Value Accuracy: 35.45454545454545\n",
      "Accuracy: 34.654545454545456\n",
      "{0: 834, 1: 2130, 2: 3236, 3: 6944, 4: 4360, 5: 3618, 6: 878}\n",
      "Value Accuracy: 35.369565217391305\n",
      "Accuracy: 34.72608695652174\n",
      "{0: 868, 1: 2214, 2: 3387, 3: 7272, 4: 4559, 5: 3793, 6: 907}\n",
      "Value Accuracy: 35.5\n",
      "Accuracy: 34.75833333333333\n",
      "{0: 899, 1: 2320, 2: 3548, 3: 7576, 4: 4764, 5: 3960, 6: 933}\n",
      "Value Accuracy: 35.56\n",
      "Accuracy: 34.788\n",
      "{0: 936, 1: 2413, 2: 3709, 3: 7859, 4: 4959, 5: 4153, 6: 971}\n",
      "Value Accuracy: 35.573076923076925\n",
      "Accuracy: 34.84230769230769\n",
      "{0: 976, 1: 2513, 2: 3847, 3: 8185, 4: 5146, 5: 4318, 6: 1015}\n",
      "Value Accuracy: 35.6037037037037\n",
      "Accuracy: 34.82222222222222\n",
      "{0: 1016, 1: 2620, 2: 4000, 3: 8502, 4: 5316, 5: 4482, 6: 1064}\n",
      "Value Accuracy: 35.66428571428571\n",
      "Accuracy: 34.81071428571428\n",
      "{0: 1050, 1: 2718, 2: 4155, 3: 8826, 4: 5518, 5: 4633, 6: 1100}\n",
      "Value Accuracy: 35.65172413793103\n",
      "Accuracy: 34.772413793103446\n",
      "{0: 1112, 1: 2810, 2: 4309, 3: 9139, 4: 5715, 5: 4789, 6: 1126}\n",
      "Value Accuracy: 35.64\n",
      "Accuracy: 34.833333333333336\n",
      "{0: 1153, 1: 2908, 2: 4435, 3: 9457, 4: 5908, 5: 4963, 6: 1176}\n",
      "Value Accuracy: 35.63548387096774\n",
      "Accuracy: 34.77741935483871\n",
      "{0: 1189, 1: 2992, 2: 4597, 3: 9766, 4: 6094, 5: 5143, 6: 1219}\n",
      "Value Accuracy: 35.64375\n",
      "Accuracy: 34.81875\n",
      "{0: 1215, 1: 3099, 2: 4768, 3: 10081, 4: 6275, 5: 5305, 6: 1257}\n",
      "Value Accuracy: 35.512121212121215\n",
      "Accuracy: 34.86969696969697\n",
      "{0: 1255, 1: 3190, 2: 4919, 3: 10395, 4: 6476, 5: 5476, 6: 1289}\n",
      "Value Accuracy: 35.53235294117647\n",
      "Accuracy: 34.88823529411765\n",
      "{0: 1290, 1: 3282, 2: 5062, 3: 10717, 4: 6663, 5: 5660, 6: 1326}\n",
      "Value Accuracy: 35.494285714285716\n",
      "Accuracy: 34.92857142857143\n",
      "{0: 1324, 1: 3385, 2: 5224, 3: 11020, 4: 6849, 5: 5824, 6: 1374}\n",
      "Value Accuracy: 35.47222222222222\n",
      "Accuracy: 34.99722222222222\n",
      "{0: 1358, 1: 3484, 2: 5374, 3: 11332, 4: 7042, 5: 5996, 6: 1414}\n",
      "Value Accuracy: 35.462162162162166\n",
      "Accuracy: 35.02972972972973\n",
      "{0: 1390, 1: 3587, 2: 5515, 3: 11637, 4: 7245, 5: 6163, 6: 1463}\n",
      "Value Accuracy: 35.492105263157896\n",
      "Accuracy: 34.97631578947368\n",
      "{0: 1431, 1: 3683, 2: 5668, 3: 11943, 4: 7428, 5: 6347, 6: 1500}\n",
      "Value Accuracy: 35.5\n",
      "Accuracy: 35.00769230769231\n",
      "{0: 1476, 1: 3772, 2: 5837, 3: 12238, 4: 7627, 5: 6516, 6: 1534}\n",
      "Value Accuracy: 35.4525\n",
      "Accuracy: 34.965\n",
      "{0: 1518, 1: 3881, 2: 5969, 3: 12545, 4: 7824, 5: 6690, 6: 1573}\n",
      "Value Accuracy: 35.36585365853659\n",
      "Accuracy: 34.96829268292683\n",
      "{0: 1555, 1: 3982, 2: 6124, 3: 12860, 4: 8014, 5: 6851, 6: 1614}\n",
      "Value Accuracy: 35.33571428571429\n",
      "Accuracy: 34.94047619047619\n",
      "{0: 1585, 1: 4060, 2: 6273, 3: 13175, 4: 8220, 5: 7029, 6: 1658}\n",
      "Value Accuracy: 35.38837209302326\n",
      "Accuracy: 34.925581395348836\n",
      "{0: 1617, 1: 4173, 2: 6401, 3: 13483, 4: 8446, 5: 7185, 6: 1695}\n",
      "Value Accuracy: 35.38409090909091\n",
      "Accuracy: 34.95454545454545\n",
      "{0: 1651, 1: 4262, 2: 6560, 3: 13800, 4: 8647, 5: 7329, 6: 1751}\n",
      "Value Accuracy: 35.38\n",
      "Accuracy: 34.87111111111111\n",
      "{0: 1688, 1: 4342, 2: 6722, 3: 14099, 4: 8875, 5: 7492, 6: 1782}\n",
      "Value Accuracy: 35.323913043478264\n",
      "Accuracy: 34.88913043478261\n",
      "{0: 1725, 1: 4447, 2: 6859, 3: 14415, 4: 9086, 5: 7645, 6: 1823}\n",
      "Value Accuracy: 35.33617021276596\n",
      "Accuracy: 34.90212765957447\n",
      "{0: 1769, 1: 4538, 2: 7010, 3: 14719, 4: 9268, 5: 7829, 6: 1867}\n",
      "Value Accuracy: 35.358333333333334\n",
      "Accuracy: 34.93125\n",
      "{0: 1815, 1: 4631, 2: 7157, 3: 15033, 4: 9463, 5: 7997, 6: 1904}\n",
      "Value Accuracy: 35.36734693877551\n",
      "Accuracy: 34.936734693877554\n",
      "{0: 1850, 1: 4715, 2: 7291, 3: 15351, 4: 9661, 5: 8170, 6: 1962}\n",
      "Value Accuracy: 35.31\n",
      "Accuracy: 34.942\n",
      "{0: 1880, 1: 4821, 2: 7430, 3: 15674, 4: 9857, 5: 8344, 6: 1994}\n",
      "Value Accuracy: 35.29019607843137\n",
      "Accuracy: 34.931372549019606\n",
      "{0: 1918, 1: 4914, 2: 7580, 3: 15970, 4: 10068, 5: 8519, 6: 2031}\n",
      "Value Accuracy: 35.28846153846154\n",
      "Accuracy: 34.93653846153846\n",
      "{0: 1959, 1: 5023, 2: 7713, 3: 16283, 4: 10276, 5: 8673, 6: 2073}\n",
      "Value Accuracy: 35.27924528301887\n",
      "Accuracy: 34.93207547169811\n",
      "{0: 1993, 1: 5116, 2: 7864, 3: 16591, 4: 10465, 5: 8853, 6: 2118}\n",
      "Value Accuracy: 35.26851851851852\n",
      "Accuracy: 34.903703703703705\n",
      "{0: 2042, 1: 5197, 2: 8011, 3: 16912, 4: 10676, 5: 9005, 6: 2157}\n",
      "Value Accuracy: 35.27454545454545\n",
      "Accuracy: 34.903636363636366\n",
      "{0: 2084, 1: 5302, 2: 8175, 3: 17203, 4: 10860, 5: 9178, 6: 2198}\n",
      "Value Accuracy: 35.246428571428574\n",
      "Accuracy: 34.894642857142856\n",
      "{0: 2131, 1: 5416, 2: 8321, 3: 17521, 4: 11038, 5: 9333, 6: 2240}\n",
      "Value Accuracy: 35.252631578947366\n",
      "Accuracy: 34.87894736842105\n",
      "{0: 2176, 1: 5518, 2: 8482, 3: 17841, 4: 11198, 5: 9519, 6: 2266}\n",
      "Value Accuracy: 35.217241379310344\n",
      "Accuracy: 34.86896551724138\n",
      "{0: 2214, 1: 5609, 2: 8642, 3: 18168, 4: 11376, 5: 9696, 6: 2295}\n",
      "Value Accuracy: 35.18305084745763\n",
      "Accuracy: 34.862711864406776\n",
      "{0: 2256, 1: 5704, 2: 8785, 3: 18487, 4: 11575, 5: 9861, 6: 2332}\n",
      "Value Accuracy: 35.151666666666664\n",
      "Accuracy: 34.843333333333334\n",
      "{0: 2298, 1: 5797, 2: 8894, 3: 18821, 4: 11800, 5: 10021, 6: 2369}\n",
      "Value Accuracy: 35.12786885245902\n",
      "Accuracy: 34.88688524590164\n",
      "{0: 2335, 1: 5881, 2: 9034, 3: 19143, 4: 11999, 5: 10199, 6: 2409}\n",
      "Value Accuracy: 35.119354838709675\n",
      "Accuracy: 34.91774193548387\n",
      "{0: 2367, 1: 5990, 2: 9190, 3: 19451, 4: 12188, 5: 10364, 6: 2450}\n",
      "Value Accuracy: 35.19206349206349\n",
      "Accuracy: 34.89206349206349\n",
      "{0: 2408, 1: 6102, 2: 9323, 3: 19726, 4: 12411, 5: 10543, 6: 2487}\n",
      "Value Accuracy: 35.1828125\n",
      "Accuracy: 34.928125\n",
      "{0: 2442, 1: 6193, 2: 9481, 3: 20038, 4: 12627, 5: 10706, 6: 2513}\n",
      "Value Accuracy: 35.18769230769231\n",
      "Accuracy: 34.924615384615386\n",
      "{0: 2477, 1: 6273, 2: 9633, 3: 20366, 4: 12836, 5: 10870, 6: 2545}\n",
      "Value Accuracy: 35.18484848484849\n",
      "Accuracy: 34.93787878787879\n",
      "{0: 2511, 1: 6368, 2: 9769, 3: 20688, 4: 13053, 5: 11029, 6: 2582}\n",
      "Value Accuracy: 35.16417910447761\n",
      "Accuracy: 34.940298507462686\n",
      "{0: 2553, 1: 6452, 2: 9928, 3: 21011, 4: 13245, 5: 11191, 6: 2620}\n",
      "Value Accuracy: 35.13823529411765\n",
      "Accuracy: 34.92794117647059\n",
      "{0: 2586, 1: 6568, 2: 10078, 3: 21297, 4: 13444, 5: 11364, 6: 2663}\n",
      "Value Accuracy: 35.118840579710145\n",
      "Accuracy: 34.902898550724636\n",
      "{0: 2629, 1: 6658, 2: 10239, 3: 21613, 4: 13634, 5: 11529, 6: 2698}\n",
      "Value Accuracy: 35.11142857142857\n",
      "Accuracy: 34.89\n",
      "{0: 2672, 1: 6740, 2: 10390, 3: 21909, 4: 13845, 5: 11698, 6: 2746}\n",
      "Value Accuracy: 35.09718309859155\n",
      "Accuracy: 34.914084507042254\n",
      "{0: 2705, 1: 6836, 2: 10545, 3: 22240, 4: 14035, 5: 11857, 6: 2782}\n",
      "Value Accuracy: 35.12083333333333\n",
      "Accuracy: 34.90555555555556\n",
      "{0: 2742, 1: 6936, 2: 10688, 3: 22563, 4: 14217, 5: 12026, 6: 2828}\n",
      "Value Accuracy: 35.12465753424657\n",
      "Accuracy: 34.88767123287671\n",
      "{0: 2772, 1: 7051, 2: 10828, 3: 22876, 4: 14409, 5: 12196, 6: 2868}\n",
      "Value Accuracy: 35.13108108108108\n",
      "Accuracy: 34.89054054054054\n",
      "{0: 2815, 1: 7145, 2: 10988, 3: 23192, 4: 14596, 5: 12358, 6: 2906}\n",
      "Value Accuracy: 35.112\n",
      "Accuracy: 34.896\n",
      "{0: 2859, 1: 7250, 2: 11098, 3: 23525, 4: 14794, 5: 12526, 6: 2948}\n",
      "Value Accuracy: 35.10657894736842\n",
      "Accuracy: 34.87894736842105\n",
      "{0: 2888, 1: 7344, 2: 11246, 3: 23854, 4: 14997, 5: 12690, 6: 2981}\n",
      "Value Accuracy: 35.127272727272725\n",
      "Accuracy: 34.85454545454545\n",
      "{0: 2929, 1: 7439, 2: 11384, 3: 24149, 4: 15202, 5: 12870, 6: 3027}\n",
      "Value Accuracy: 35.093589743589746\n",
      "Accuracy: 34.83461538461538\n",
      "{0: 2961, 1: 7553, 2: 11545, 3: 24470, 4: 15389, 5: 13017, 6: 3065}\n",
      "Value Accuracy: 35.1126582278481\n",
      "Accuracy: 34.8506329113924\n",
      "{0: 2995, 1: 7647, 2: 11690, 3: 24786, 4: 15585, 5: 13191, 6: 3106}\n",
      "Value Accuracy: 35.125\n",
      "Accuracy: 34.82625\n",
      "{0: 3029, 1: 7753, 2: 11844, 3: 25123, 4: 15768, 5: 13334, 6: 3149}\n",
      "Value Accuracy: 35.09506172839506\n",
      "Accuracy: 34.806172839506175\n",
      "{0: 3070, 1: 7844, 2: 12014, 3: 25435, 4: 15979, 5: 13472, 6: 3186}\n",
      "Value Accuracy: 35.045121951219514\n",
      "Accuracy: 34.78536585365854\n",
      "{0: 3106, 1: 7941, 2: 12164, 3: 25737, 4: 16188, 5: 13633, 6: 3231}\n",
      "Value Accuracy: 35.04819277108434\n",
      "Accuracy: 34.82409638554217\n",
      "{0: 3147, 1: 8039, 2: 12314, 3: 26041, 4: 16384, 5: 13812, 6: 3263}\n",
      "Value Accuracy: 35.055952380952384\n",
      "Accuracy: 34.81547619047619\n",
      "{0: 3186, 1: 8140, 2: 12464, 3: 26360, 4: 16571, 5: 13966, 6: 3313}\n",
      "Value Accuracy: 35.04235294117647\n",
      "Accuracy: 34.805882352941175\n",
      "{0: 3228, 1: 8237, 2: 12596, 3: 26675, 4: 16787, 5: 14132, 6: 3345}\n",
      "Value Accuracy: 35.019767441860466\n",
      "Accuracy: 34.78720930232558\n",
      "{0: 3259, 1: 8329, 2: 12740, 3: 26975, 4: 16999, 5: 14303, 6: 3395}\n",
      "Value Accuracy: 34.99425287356322\n",
      "Accuracy: 34.758620689655174\n",
      "{0: 3299, 1: 8418, 2: 12895, 3: 27282, 4: 17191, 5: 14466, 6: 3449}\n",
      "Value Accuracy: 35.023863636363636\n",
      "Accuracy: 34.75340909090909\n",
      "{0: 3329, 1: 8506, 2: 13042, 3: 27586, 4: 17393, 5: 14648, 6: 3496}\n",
      "Value Accuracy: 35.0314606741573\n",
      "Accuracy: 34.76741573033708\n",
      "{0: 3369, 1: 8588, 2: 13210, 3: 27894, 4: 17572, 5: 14830, 6: 3537}\n",
      "Value Accuracy: 35.032222222222224\n",
      "Accuracy: 34.73222222222222\n",
      "{0: 3397, 1: 8671, 2: 13360, 3: 28232, 4: 17760, 5: 15009, 6: 3571}\n",
      "Value Accuracy: 35.06043956043956\n",
      "Accuracy: 34.74065934065934\n",
      "{0: 3427, 1: 8774, 2: 13514, 3: 28549, 4: 17955, 5: 15164, 6: 3617}\n",
      "Value Accuracy: 35.06195652173913\n",
      "Accuracy: 34.721739130434784\n",
      "{0: 3457, 1: 8872, 2: 13678, 3: 28861, 4: 18144, 5: 15334, 6: 3654}\n",
      "Value Accuracy: 35.097849462365595\n",
      "Accuracy: 34.715053763440864\n",
      "{0: 3493, 1: 8964, 2: 13829, 3: 29185, 4: 18344, 5: 15495, 6: 3690}\n",
      "Value Accuracy: 35.10425531914893\n",
      "Accuracy: 34.71595744680851\n",
      "{0: 3537, 1: 9060, 2: 13989, 3: 29516, 4: 18517, 5: 15653, 6: 3728}\n",
      "Value Accuracy: 35.07473684210526\n",
      "Accuracy: 34.718947368421055\n",
      "{0: 3566, 1: 9151, 2: 14148, 3: 29857, 4: 18700, 5: 15814, 6: 3764}\n",
      "Value Accuracy: 35.08020833333333\n",
      "Accuracy: 34.72708333333333\n",
      "{0: 3603, 1: 9260, 2: 14287, 3: 30166, 4: 18901, 5: 15977, 6: 3806}\n",
      "Value Accuracy: 35.095876288659795\n",
      "Accuracy: 34.717525773195874\n",
      "{0: 3640, 1: 9343, 2: 14425, 3: 30497, 4: 19097, 5: 16141, 6: 3857}\n",
      "Value Accuracy: 35.08265306122449\n",
      "Accuracy: 34.704081632653065\n",
      "{0: 3673, 1: 9451, 2: 14573, 3: 30819, 4: 19290, 5: 16298, 6: 3896}\n",
      "Value Accuracy: 35.061616161616165\n",
      "Accuracy: 34.670707070707074\n",
      "{0: 3699, 1: 9542, 2: 14727, 3: 31141, 4: 19495, 5: 16461, 6: 3935}\n",
      "Value Accuracy: 35.061\n",
      "Accuracy: 34.689\n",
      "{0: 3738, 1: 9639, 2: 14882, 3: 31462, 4: 19692, 5: 16615, 6: 3972}\n",
      "Value Accuracy: 35.05346534653465\n",
      "Accuracy: 34.68316831683168\n",
      "{0: 3772, 1: 9735, 2: 15027, 3: 31778, 4: 19904, 5: 16774, 6: 4010}\n",
      "Value Accuracy: 35.043137254901964\n",
      "Accuracy: 34.71862745098039\n",
      "{0: 3812, 1: 9840, 2: 15174, 3: 32085, 4: 20104, 5: 16938, 6: 4047}\n",
      "Value Accuracy: 35.03106796116505\n",
      "Accuracy: 34.71747572815534\n",
      "{0: 3862, 1: 9935, 2: 15315, 3: 32399, 4: 20299, 5: 17101, 6: 4089}\n",
      "Value Accuracy: 34.989423076923075\n",
      "Accuracy: 34.72788461538462\n",
      "{0: 3894, 1: 10022, 2: 15474, 3: 32729, 4: 20485, 5: 17264, 6: 4132}\n",
      "Value Accuracy: 34.98095238095238\n",
      "Accuracy: 34.71619047619048\n",
      "{0: 3918, 1: 10116, 2: 15613, 3: 33043, 4: 20701, 5: 17443, 6: 4166}\n",
      "Value Accuracy: 34.9566037735849\n",
      "Accuracy: 34.716037735849056\n",
      "{0: 3965, 1: 10214, 2: 15767, 3: 33361, 4: 20882, 5: 17602, 6: 4209}\n",
      "Value Accuracy: 34.95514018691589\n",
      "Accuracy: 34.70841121495327\n",
      "{0: 4014, 1: 10299, 2: 15906, 3: 33691, 4: 21069, 5: 17767, 6: 4254}\n",
      "Value Accuracy: 34.95740740740741\n",
      "Accuracy: 34.69722222222222\n",
      "{0: 4045, 1: 10400, 2: 16070, 3: 34002, 4: 21274, 5: 17917, 6: 4292}\n",
      "Value Accuracy: 34.94862385321101\n",
      "Accuracy: 34.68807339449541\n",
      "{0: 4086, 1: 10486, 2: 16214, 3: 34321, 4: 21479, 5: 18084, 6: 4330}\n",
      "Value Accuracy: 34.94090909090909\n",
      "Accuracy: 34.67181818181818\n",
      "{0: 4129, 1: 10600, 2: 16355, 3: 34629, 4: 21672, 5: 18244, 6: 4371}\n",
      "Value Accuracy: 34.935135135135134\n",
      "Accuracy: 34.66576576576576\n",
      "{0: 4165, 1: 10698, 2: 16503, 3: 34964, 4: 21866, 5: 18399, 6: 4405}\n",
      "Value Accuracy: 34.93660714285714\n",
      "Accuracy: 34.6625\n",
      "{0: 4203, 1: 10805, 2: 16645, 3: 35269, 4: 22065, 5: 18566, 6: 4447}\n",
      "Value Accuracy: 34.93628318584071\n",
      "Accuracy: 34.66548672566372\n",
      "{0: 4240, 1: 10898, 2: 16793, 3: 35560, 4: 22280, 5: 18737, 6: 4492}\n",
      "Value Accuracy: 34.95175438596491\n",
      "Accuracy: 34.65877192982456\n",
      "{0: 4274, 1: 11001, 2: 16936, 3: 35882, 4: 22473, 5: 18903, 6: 4531}\n",
      "Value Accuracy: 34.958260869565216\n",
      "Accuracy: 34.65217391304348\n",
      "{0: 4307, 1: 11111, 2: 17097, 3: 36187, 4: 22667, 5: 19073, 6: 4558}\n",
      "Value Accuracy: 34.93793103448276\n",
      "Accuracy: 34.64224137931034\n",
      "{0: 4342, 1: 11202, 2: 17229, 3: 36538, 4: 22852, 5: 19243, 6: 4594}\n",
      "Value Accuracy: 34.919658119658116\n",
      "Accuracy: 34.616239316239316\n",
      "{0: 4371, 1: 11308, 2: 17376, 3: 36838, 4: 23050, 5: 19418, 6: 4639}\n",
      "Value Accuracy: 34.938983050847455\n",
      "Accuracy: 34.6093220338983\n",
      "{0: 4403, 1: 11391, 2: 17544, 3: 37137, 4: 23253, 5: 19589, 6: 4683}\n",
      "Value Accuracy: 34.95378151260504\n",
      "Accuracy: 34.59411764705882\n",
      "{0: 4445, 1: 11482, 2: 17685, 3: 37461, 4: 23440, 5: 19757, 6: 4730}\n",
      "Value Accuracy: 34.965833333333336\n",
      "Accuracy: 34.59583333333333\n",
      "{0: 4482, 1: 11574, 2: 17837, 3: 37794, 4: 23616, 5: 19927, 6: 4770}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     12\u001b[0m policy \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m7\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m policy_distribution[\u001b[38;5;241m0\u001b[39m][i] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m predicted_policy, predicted_value \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m predicted_policy\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m moves[predicted\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/src/alpha_connect/model.py:96\u001b[0m, in \u001b[0;36mAlphaZeroModelConnect4.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 96\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# flat = x.view(x.size(0), -1)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# print(flat.shape)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_head(x)\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/src/alpha_connect/model.py:32\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/src/alpha_connect/model.py:19\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:181\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    184\u001b[0m     bn_training,\n\u001b[1;32m    185\u001b[0m     exponential_average_factor,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    187\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/alpha-connect/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1675\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1677\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "model.eval()\n",
    "\n",
    "correct_value = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "moves = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0}\n",
    "i = 0\n",
    "display = 5\n",
    "for x, policy_distribution, value in loader:\n",
    "    i += 1\n",
    "    policy = [i for i in range(7) if policy_distribution[0][i] != 0]\n",
    "    predicted_policy, predicted_value = model(x)\n",
    "    _, predicted = predicted_policy.max(1)\n",
    "    moves[predicted.item()] += 1\n",
    "    total += 1\n",
    "    correct += 1 if (predicted in policy) else 0\n",
    "\n",
    "    correct_value += 1 if torch.abs(predicted_value - value) < 0.5 else 0\n",
    "    if display > 0:\n",
    "        print(f\"Policy: {list(policy_distribution)[0]}\")\n",
    "        print(f\"Predicted policy: {predicted_policy[0]}\")\n",
    "        print(f\"Value: {int(value)}\")\n",
    "        print(f\"Predicted value: {float(predicted_value)}\")\n",
    "        display -= 1\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Value Accuracy: {100*correct_value/total}\")\n",
    "        print(f\"Accuracy: {100*correct/total}\")\n",
    "        print(moves)\n",
    "\n",
    "print(f\"Value Accuracy: {100*correct_value/total}\")\n",
    "print(f\"Accuracy: {100*correct/total}\")\n",
    "print(moves)\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
